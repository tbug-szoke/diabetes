{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MRIwosP9l0ve"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from config import db_password \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.simplefilter(action = \"ignore\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to diabetes RDS database\n",
        "# Define connection\n",
        "DATABASES = {\n",
        "    'production':{\n",
        "        'NAME': 'Diabetes_db',\n",
        "        'USER': 'postgres',\n",
        "        'PASSWORD': db_password,\n",
        "        'HOST': 'diabetesdb.cwyccvgtauvd.us-east-2.rds.amazonaws.com',\n",
        "        'PORT': 5432,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Choose the database\n",
        "db = DATABASES['production']\n",
        "\n",
        "# construct an engine connection string\n",
        "engine_string = \"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(\n",
        "    user = db['USER'],\n",
        "    password = db['PASSWORD'],\n",
        "    host = db['HOST'],\n",
        "    port = db['PORT'],\n",
        "    database = db['NAME'],\n",
        ")\n",
        "\n",
        "# create sqlalchemy engine\n",
        "engine = create_engine(engine_string)\n",
        "\n",
        "# read a table from database into pandas dataframe, replace \"tablename\" with your table name\n",
        "df = pd.read_sql_table('diabetes',engine)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmzMRXt0ZIWl",
        "outputId": "31dad93e-fbd5-487c-b8bf-c17c343a147a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(945188, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove NaN Values from all other fields (Features); replace with a value that is unused in the raw data set (aka 100)\n",
        "df.fillna(100, inplace=True)"
      ],
      "metadata": {
        "id": "T_fvrvrvnNFp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into X (features) and y (target):\n",
        "\n",
        "y = df['diabete3']\n",
        "X = df.drop(columns=['diabete3','id','_state','iyear','htm4','wtkg3'])\n",
        "X.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "r_yAmFqxnTsN",
        "outputId": "06198355-de6d-4cc6-ae84-1d62dff2adf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             genhlth       physhlth       menthlth       poorhlth  \\\n",
              "count  945188.000000  945188.000000  945188.000000  945188.000000   \n",
              "mean        2.592309      60.631176      64.399970      77.237957   \n",
              "std         1.154237      37.041350      35.926294      35.066144   \n",
              "min         1.000000       1.000000       1.000000       1.000000   \n",
              "25%         2.000000      15.000000      25.000000      88.000000   \n",
              "50%         3.000000      88.000000      88.000000      88.000000   \n",
              "75%         3.000000      88.000000      88.000000     100.000000   \n",
              "max       100.000000     100.000000      99.000000     100.000000   \n",
              "\n",
              "            hlthpln1       persdoc2        medcost       checkup1  \\\n",
              "count  945188.000000  945188.000000  945188.000000  945188.000000   \n",
              "mean        1.119785       1.391746       1.900935       1.601569   \n",
              "std         0.504575       0.817551       0.438216       1.270311   \n",
              "min         1.000000       1.000000       1.000000       1.000000   \n",
              "25%         1.000000       1.000000       2.000000       1.000000   \n",
              "50%         1.000000       1.000000       2.000000       1.000000   \n",
              "75%         1.000000       1.000000       2.000000       2.000000   \n",
              "max         9.000000       9.000000     100.000000     100.000000   \n",
              "\n",
              "             bphigh4        toldhi2  ...         adfail        adthink  \\\n",
              "count  945188.000000  945188.000000  ...  945188.000000  945188.000000   \n",
              "mean        2.215451      15.056277  ...      99.036208      99.093822   \n",
              "std         1.060227      33.788468  ...       7.721615       7.306799   \n",
              "min         1.000000       1.000000  ...       1.000000       1.000000   \n",
              "25%         1.000000       1.000000  ...     100.000000     100.000000   \n",
              "50%         3.000000       2.000000  ...     100.000000     100.000000   \n",
              "75%         3.000000       2.000000  ...     100.000000     100.000000   \n",
              "max       100.000000     100.000000  ...     100.000000     100.000000   \n",
              "\n",
              "              admove        mistmnt        adanxev          _race  \\\n",
              "count  945188.000000  945188.000000  945188.000000  945188.000000   \n",
              "mean       99.253851      96.388232      96.389104       1.990272   \n",
              "std         6.044232      18.475206      18.474111       2.495198   \n",
              "min         1.000000       1.000000       1.000000       1.000000   \n",
              "25%       100.000000     100.000000     100.000000       1.000000   \n",
              "50%       100.000000     100.000000     100.000000       1.000000   \n",
              "75%       100.000000     100.000000     100.000000       1.000000   \n",
              "max       100.000000     100.000000     100.000000     100.000000   \n",
              "\n",
              "              _age_g          _bmi5      _frutsum      _vegesum  \n",
              "count  945188.000000  945188.000000  9.451880e+05  9.451880e+05  \n",
              "mean        4.422571    2603.159951  1.382295e+02  1.845304e+02  \n",
              "std         1.526921     908.311942  1.311997e+02  1.438683e+02  \n",
              "min         1.000000     100.000000  5.397605e-79  5.397605e-79  \n",
              "25%         3.000000    2289.000000  6.000000e+01  1.000000e+02  \n",
              "50%         5.000000    2645.000000  1.000000e+02  1.570000e+02  \n",
              "75%         6.000000    3034.000000  2.000000e+02  2.330000e+02  \n",
              "max         6.000000    9995.000000  1.500000e+04  2.046000e+04  \n",
              "\n",
              "[8 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b82def16-6a30-4daf-b6fd-4e35295f19f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genhlth</th>\n",
              "      <th>physhlth</th>\n",
              "      <th>menthlth</th>\n",
              "      <th>poorhlth</th>\n",
              "      <th>hlthpln1</th>\n",
              "      <th>persdoc2</th>\n",
              "      <th>medcost</th>\n",
              "      <th>checkup1</th>\n",
              "      <th>bphigh4</th>\n",
              "      <th>toldhi2</th>\n",
              "      <th>...</th>\n",
              "      <th>adfail</th>\n",
              "      <th>adthink</th>\n",
              "      <th>admove</th>\n",
              "      <th>mistmnt</th>\n",
              "      <th>adanxev</th>\n",
              "      <th>_race</th>\n",
              "      <th>_age_g</th>\n",
              "      <th>_bmi5</th>\n",
              "      <th>_frutsum</th>\n",
              "      <th>_vegesum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>945188.000000</td>\n",
              "      <td>9.451880e+05</td>\n",
              "      <td>9.451880e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.592309</td>\n",
              "      <td>60.631176</td>\n",
              "      <td>64.399970</td>\n",
              "      <td>77.237957</td>\n",
              "      <td>1.119785</td>\n",
              "      <td>1.391746</td>\n",
              "      <td>1.900935</td>\n",
              "      <td>1.601569</td>\n",
              "      <td>2.215451</td>\n",
              "      <td>15.056277</td>\n",
              "      <td>...</td>\n",
              "      <td>99.036208</td>\n",
              "      <td>99.093822</td>\n",
              "      <td>99.253851</td>\n",
              "      <td>96.388232</td>\n",
              "      <td>96.389104</td>\n",
              "      <td>1.990272</td>\n",
              "      <td>4.422571</td>\n",
              "      <td>2603.159951</td>\n",
              "      <td>1.382295e+02</td>\n",
              "      <td>1.845304e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.154237</td>\n",
              "      <td>37.041350</td>\n",
              "      <td>35.926294</td>\n",
              "      <td>35.066144</td>\n",
              "      <td>0.504575</td>\n",
              "      <td>0.817551</td>\n",
              "      <td>0.438216</td>\n",
              "      <td>1.270311</td>\n",
              "      <td>1.060227</td>\n",
              "      <td>33.788468</td>\n",
              "      <td>...</td>\n",
              "      <td>7.721615</td>\n",
              "      <td>7.306799</td>\n",
              "      <td>6.044232</td>\n",
              "      <td>18.475206</td>\n",
              "      <td>18.474111</td>\n",
              "      <td>2.495198</td>\n",
              "      <td>1.526921</td>\n",
              "      <td>908.311942</td>\n",
              "      <td>1.311997e+02</td>\n",
              "      <td>1.438683e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>5.397605e-79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2289.000000</td>\n",
              "      <td>6.000000e+01</td>\n",
              "      <td>1.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2645.000000</td>\n",
              "      <td>1.000000e+02</td>\n",
              "      <td>1.570000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3034.000000</td>\n",
              "      <td>2.000000e+02</td>\n",
              "      <td>2.330000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9995.000000</td>\n",
              "      <td>1.500000e+04</td>\n",
              "      <td>2.046000e+04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b82def16-6a30-4daf-b6fd-4e35295f19f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b82def16-6a30-4daf-b6fd-4e35295f19f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b82def16-6a30-4daf-b6fd-4e35295f19f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check balance of target column\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPjyDuVInYep",
        "outputId": "93b84c19-cb73-4fb0-8050-adc61839f308"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    809602\n",
              "1.0    119717\n",
              "4.0     15869\n",
              "Name: diabete3, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform y values to 0 = no diabetes; 1 = yes, diabetes.  Per BRFSS codebook 4 = prediabetes and we consider this as 'yes, diabetes'\n",
        "\n",
        "y = y.replace({4:1})\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVALYjvWngn_",
        "outputId": "a2f2e44e-7c15-420c-c12a-5f967b530364"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    809602\n",
              "1.0    135586\n",
              "Name: diabete3, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing data sets\n",
        "# Remove test size paramenter\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "\n",
        "Counter(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr4A1lmyniA7",
        "outputId": "bec256b4-26ae-4392-de79-efcfcb9838d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0.0: 606872, 1.0: 102019})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# Fitting the Standard Scaler with the training data.\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scaling the data.\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "0UZMKZmenl4c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 92\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfkTbIzwnp1N",
        "outputId": "62f07437-78f8-4f84-f098-bbbe8d2056ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 92)                4324      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 93        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,417\n",
            "Trainable params: 4,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "1dNTjYbZokVE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train,y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zZGHs1golsc",
        "outputId": "ceafaaa4-9ead-421a-c29a-9e554e1116bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22153/22153 [==============================] - 45s 2ms/step - loss: 0.9348 - accuracy: 0.8095\n",
            "Epoch 2/100\n",
            "22153/22153 [==============================] - 43s 2ms/step - loss: 0.5904 - accuracy: 0.8219\n",
            "Epoch 3/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.4613 - accuracy: 0.8339\n",
            "Epoch 4/100\n",
            "22153/22153 [==============================] - 43s 2ms/step - loss: 0.3759 - accuracy: 0.8482\n",
            "Epoch 5/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3426 - accuracy: 0.8573\n",
            "Epoch 6/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3337 - accuracy: 0.8597\n",
            "Epoch 7/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3322 - accuracy: 0.8598\n",
            "Epoch 8/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3306 - accuracy: 0.8601\n",
            "Epoch 9/100\n",
            "22153/22153 [==============================] - 43s 2ms/step - loss: 0.3297 - accuracy: 0.8600\n",
            "Epoch 10/100\n",
            "22153/22153 [==============================] - 44s 2ms/step - loss: 0.3296 - accuracy: 0.8603\n",
            "Epoch 11/100\n",
            "22153/22153 [==============================] - 43s 2ms/step - loss: 0.3293 - accuracy: 0.8603\n",
            "Epoch 12/100\n",
            "22153/22153 [==============================] - 43s 2ms/step - loss: 0.3287 - accuracy: 0.8605\n",
            "Epoch 13/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3289 - accuracy: 0.8607\n",
            "Epoch 14/100\n",
            "22153/22153 [==============================] - 43s 2ms/step - loss: 0.3291 - accuracy: 0.8603\n",
            "Epoch 15/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3287 - accuracy: 0.8602\n",
            "Epoch 16/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3286 - accuracy: 0.8603\n",
            "Epoch 17/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3281 - accuracy: 0.8606\n",
            "Epoch 18/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3282 - accuracy: 0.8608\n",
            "Epoch 19/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3282 - accuracy: 0.8605\n",
            "Epoch 20/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3280 - accuracy: 0.8605\n",
            "Epoch 21/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3280 - accuracy: 0.8605\n",
            "Epoch 22/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3280 - accuracy: 0.8605\n",
            "Epoch 23/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3278 - accuracy: 0.8606\n",
            "Epoch 24/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3278 - accuracy: 0.8606\n",
            "Epoch 25/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3278 - accuracy: 0.8609\n",
            "Epoch 26/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3277 - accuracy: 0.8608\n",
            "Epoch 27/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3276 - accuracy: 0.8607\n",
            "Epoch 28/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8608\n",
            "Epoch 29/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3278 - accuracy: 0.8607\n",
            "Epoch 30/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3274 - accuracy: 0.8606\n",
            "Epoch 31/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3277 - accuracy: 0.8607\n",
            "Epoch 32/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8609\n",
            "Epoch 33/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3274 - accuracy: 0.8606\n",
            "Epoch 34/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8604\n",
            "Epoch 35/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3274 - accuracy: 0.8608\n",
            "Epoch 36/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8608\n",
            "Epoch 37/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3273 - accuracy: 0.8608\n",
            "Epoch 38/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8606\n",
            "Epoch 39/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3271 - accuracy: 0.8606\n",
            "Epoch 40/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8609\n",
            "Epoch 41/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3272 - accuracy: 0.8608\n",
            "Epoch 42/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3273 - accuracy: 0.8607\n",
            "Epoch 43/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3273 - accuracy: 0.8609\n",
            "Epoch 44/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3274 - accuracy: 0.8608\n",
            "Epoch 45/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3273 - accuracy: 0.8609\n",
            "Epoch 46/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3271 - accuracy: 0.8606\n",
            "Epoch 47/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3272 - accuracy: 0.8609\n",
            "Epoch 48/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3273 - accuracy: 0.8609\n",
            "Epoch 49/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3275 - accuracy: 0.8607\n",
            "Epoch 50/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8612\n",
            "Epoch 51/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3273 - accuracy: 0.8608\n",
            "Epoch 52/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3273 - accuracy: 0.8608\n",
            "Epoch 53/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3273 - accuracy: 0.8609\n",
            "Epoch 54/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3272 - accuracy: 0.8610\n",
            "Epoch 55/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3273 - accuracy: 0.8609\n",
            "Epoch 56/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3271 - accuracy: 0.8608\n",
            "Epoch 57/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3272 - accuracy: 0.8608\n",
            "Epoch 58/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3271 - accuracy: 0.8609\n",
            "Epoch 59/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3271 - accuracy: 0.8609\n",
            "Epoch 60/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 61/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3271 - accuracy: 0.8607\n",
            "Epoch 62/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3271 - accuracy: 0.8609\n",
            "Epoch 63/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3272 - accuracy: 0.8609\n",
            "Epoch 64/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3271 - accuracy: 0.8609\n",
            "Epoch 65/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3269 - accuracy: 0.8609\n",
            "Epoch 66/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3271 - accuracy: 0.8610\n",
            "Epoch 67/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3271 - accuracy: 0.8607\n",
            "Epoch 68/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3273 - accuracy: 0.8609\n",
            "Epoch 69/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3272 - accuracy: 0.8608\n",
            "Epoch 70/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8611\n",
            "Epoch 71/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8611\n",
            "Epoch 72/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 73/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 74/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 75/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 76/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3272 - accuracy: 0.8609\n",
            "Epoch 77/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3271 - accuracy: 0.8609\n",
            "Epoch 78/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8612\n",
            "Epoch 79/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 80/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 81/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3271 - accuracy: 0.8610\n",
            "Epoch 82/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 83/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3268 - accuracy: 0.8610\n",
            "Epoch 84/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 85/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3269 - accuracy: 0.8611\n",
            "Epoch 86/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3270 - accuracy: 0.8609\n",
            "Epoch 87/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 88/100\n",
            "22153/22153 [==============================] - 40s 2ms/step - loss: 0.3272 - accuracy: 0.8609\n",
            "Epoch 89/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3268 - accuracy: 0.8611\n",
            "Epoch 90/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 91/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 92/100\n",
            "22153/22153 [==============================] - 41s 2ms/step - loss: 0.3270 - accuracy: 0.8611\n",
            "Epoch 93/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3269 - accuracy: 0.8611\n",
            "Epoch 94/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3269 - accuracy: 0.8610\n",
            "Epoch 95/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3269 - accuracy: 0.8607\n",
            "Epoch 96/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3268 - accuracy: 0.8608\n",
            "Epoch 97/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3269 - accuracy: 0.8611\n",
            "Epoch 98/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3270 - accuracy: 0.8610\n",
            "Epoch 99/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3269 - accuracy: 0.8609\n",
            "Epoch 100/100\n",
            "22153/22153 [==============================] - 42s 2ms/step - loss: 0.3270 - accuracy: 0.8611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The NN took 1h 9m 23s to complete and the accuracies were similar to those from the RandomForestClassifier, \n",
        "# even thogh the RFC took only 1m 47.8 seconds to create and fit"
      ],
      "metadata": {
        "id": "SMJZgl3Vtqmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS5t9TFpuAZm",
        "outputId": "9c931fd9-5fd6-48ee-b27d-598b758fda8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7385/7385 - 9s - loss: 0.3219 - accuracy: 0.8633 - 9s/epoch - 1ms/step\n",
            "Loss: 0.321900337934494, Accuracy: 0.8632695078849792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "\n",
        "# Plot the loss\n",
        "history_df.plot(y=\"loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "R4jzFzhYuZDy",
        "outputId": "323f6d53-c3ce-4dba-a94b-2ee88c510ce2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd29f279700>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "SFwWtp3IubEN",
        "outputId": "2d08c023-9997-4202-95cb-b82f45e91577"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd29f1b3490>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try the Nueral Network on the simplest data set that we evaluated with the RFC model\n",
        "X=df[['_age_g','sex','bphigh4','exerany2','_race','_bmi5']]\n",
        "X.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4rf4I9YBunzF",
        "outputId": "5c6ae807-8e89-413e-d1a9-0867ae771258"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _age_g  sex  bphigh4  exerany2  _race   _bmi5\n",
              "0     5.0  2.0      1.0       2.0    1.0  4018.0\n",
              "1     4.0  2.0      3.0       1.0    1.0  2509.0\n",
              "2     6.0  2.0      3.0     100.0    1.0  2204.0\n",
              "3     5.0  2.0      1.0       2.0    1.0  2819.0\n",
              "4     5.0  2.0      3.0       2.0    1.0  2437.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6981efdc-2344-4bc7-b292-075a33c60526\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_age_g</th>\n",
              "      <th>sex</th>\n",
              "      <th>bphigh4</th>\n",
              "      <th>exerany2</th>\n",
              "      <th>_race</th>\n",
              "      <th>_bmi5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4018.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2509.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2204.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2819.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2437.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6981efdc-2344-4bc7-b292-075a33c60526')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6981efdc-2344-4bc7-b292-075a33c60526 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6981efdc-2344-4bc7-b292-075a33c60526');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run model\n",
        "\n",
        "# Split into training and testing data sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "\n",
        "Counter(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh4nq_O0vqPe",
        "outputId": "f51b9d36-f50a-4651-9b73-8dd05c6112fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0.0: 607087, 1.0: 101804})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# Fitting the Standard Scaler with the training data.\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scaling the data.\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "vh0h89suvxKr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 12\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4t7Jxxfvy1e",
        "outputId": "78b7b984-eb68-4ece-fd33-1f3b66f241ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 12)                84        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97\n",
            "Trainable params: 97\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "S_EWzggGv9BF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model (reducing epochs based on how quickly accuracy was achieved in the first model)\n",
        "fit_model = nn.fit(X_train,y_train,epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-fZeEApwCt1",
        "outputId": "06849eae-ba71-4eba-b1dd-0a9d43a4a6ee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "22153/22153 [==============================] - 38s 2ms/step - loss: 9.2128 - accuracy: 0.8365\n",
            "Epoch 2/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3837 - accuracy: 0.8478\n",
            "Epoch 3/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3761 - accuracy: 0.8494\n",
            "Epoch 4/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3723 - accuracy: 0.8508\n",
            "Epoch 5/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3664 - accuracy: 0.8527\n",
            "Epoch 6/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3599 - accuracy: 0.8547\n",
            "Epoch 7/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3540 - accuracy: 0.8562\n",
            "Epoch 8/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3519 - accuracy: 0.8563\n",
            "Epoch 9/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3513 - accuracy: 0.8566\n",
            "Epoch 10/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3506 - accuracy: 0.8569\n",
            "Epoch 11/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3504 - accuracy: 0.8567\n",
            "Epoch 12/25\n",
            "22153/22153 [==============================] - 34s 2ms/step - loss: 0.3503 - accuracy: 0.8567\n",
            "Epoch 13/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3499 - accuracy: 0.8566\n",
            "Epoch 14/25\n",
            "22153/22153 [==============================] - 36s 2ms/step - loss: 0.3498 - accuracy: 0.8566\n",
            "Epoch 15/25\n",
            "22153/22153 [==============================] - 36s 2ms/step - loss: 0.3496 - accuracy: 0.8569\n",
            "Epoch 16/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3495 - accuracy: 0.8569\n",
            "Epoch 17/25\n",
            "22153/22153 [==============================] - 36s 2ms/step - loss: 0.3496 - accuracy: 0.8569\n",
            "Epoch 18/25\n",
            "22153/22153 [==============================] - 36s 2ms/step - loss: 0.3494 - accuracy: 0.8569\n",
            "Epoch 19/25\n",
            "22153/22153 [==============================] - 36s 2ms/step - loss: 0.3493 - accuracy: 0.8570\n",
            "Epoch 20/25\n",
            "22153/22153 [==============================] - 36s 2ms/step - loss: 0.3492 - accuracy: 0.8569\n",
            "Epoch 21/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3492 - accuracy: 0.8570\n",
            "Epoch 22/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3490 - accuracy: 0.8571\n",
            "Epoch 23/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3490 - accuracy: 0.8571\n",
            "Epoch 24/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3491 - accuracy: 0.8570\n",
            "Epoch 25/25\n",
            "22153/22153 [==============================] - 35s 2ms/step - loss: 0.3489 - accuracy: 0.8569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GS6wWth0bY5",
        "outputId": "2ab1258d-a71f-4042-cc0f-9fff4866be11"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7385/7385 - 8s - loss: 0.3521 - accuracy: 0.8556 - 8s/epoch - 1ms/step\n",
            "Loss: 0.3521304130554199, Accuracy: 0.8556308150291443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhG3F-xC0kiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}